- [C++](#c)
  - [01.malloc和new的区别](#01malloc和new的区别)
  - [02.malloc的底层实现](#02malloc的底层实现)
  - [03.C++头文件“<>”和“ “” ”的区别](#03c头文件和--的区别)
  - [04.堆和栈的区别](#04堆和栈的区别)
  - [05.内存泄漏](#05内存泄漏)
  - [06.常用设计模式](#06常用设计模式)
- [操作系统](#操作系统)
  - [01.进程的三种状态](#01进程的三种状态)
  - [02.进程和线程的区别](#02进程和线程的区别)
  - [03. 线程和进程的同步机制](#03-线程和进程的同步机制)
    - [线程间通信](#线程间通信)
    - [进程间通信](#进程间通信)
  - [04.虚拟地址](#04虚拟地址)
  - [05.父子进程间的关系](#05父子进程间的关系)
- [计算机网络](#计算机网络)
  - [01.TCP三次握手和四次挥手](#01tcp三次握手和四次挥手)
    - [TCP基本认识](#tcp基本认识)
    - [UDP 和 TCP 的区别与应用场景](#udp-和-tcp-的区别与应用场景)
    - [三次握手](#三次握手)
    - [四次挥手](#四次挥手)
  - [02.网络编程常用的API](#02网络编程常用的api)
  - [03.IO多路复用](#03io多路复用)
# C++

## 01.malloc和new的区别

1. **申请的内存所在位置**

   new操作符是从自由存储区上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请的，该内存就是自由存储区，自由存储区可以是堆，也可以是静态存储区，这要看operator new在哪里分配的，而堆是操作系统上的术语，是操作系统所维护的一块特殊内存

2. **返回类型安全性**

   new操作符内存分配成功时，返回的是对象类型的指针，类型严格于对象匹配，无须进行类型转换

   而malloc内存分配成功返回的是void*，需要通过类型强转为我们需要的类型

3. **内存分配失败时的返回值**

   new内存分配失败时会抛出异常（bad_alloc），malloc分配内存失败时返回NULL

4. **是否需要指定内存大小**

   使用new操作符申请内存分配时无需指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显示指出所需内存的大小

5. **是否调用构造函数/析构函数**

   使用new操作符来分配对象内存时会经历三个步骤

   第一步：调用operator new函数（对于数组是operator new[]）分配一块足够大的，未使用的内存空间以便于存储特定类型的对象
   第二步：编译器运行相应的构造函数以构造对象，并为其传入初值
   第三步：对象构造完成后，返回一个指向该对象的指针
   使用delete操作符来释放对象内存时会经历两个步骤

   第一步：调用对象的析构函数
   第二步：编译器调用operator delete（或operator delete[]）函数释放内存空间

   而malloc不会调用对象的构造函数或是析构函数

6. **对数组的处理**

   C++提供了new[]和delete[]来专门处理数组类型，new[]会分别调用构造函数初始化每一个数组元素，释放对象时调用析构函数，注意new[]和delete[]需要配套使用，否则会造成内存泄漏

   malloc并不需要知道这块内存上面存了什么，如要我们要分配一个数组的内存，需要我们手动自定数组的大小

7. **new于malloc是否可以互相调用**

   new底层调用的时malloc，而malloc的实现不能去调用new

8. **是否可以被重载**

   operator new / opertor delete可以被重载

   malloc / free并不允许重载

9. **能够直观地重新分配内存**

   使用malloc分配内存后，如果使用地过程中发现内存不足，可以使用realloc函数进行内存重新分配实现内存地扩充

   new没有这样方法来扩充内存

   **总结一下**

   malloc就好像是给你一块内存，你拿它去随便做什么

   new不仅给你一块内存，还帮你把这块内存划分好（new[]）并初始化（构造函数） 

## [02.malloc的底层实现](https://xiaolincoding.com/os/3_memory/malloc.html#free-%E9%87%8A%E6%94%BE%E5%86%85%E5%AD%98-%E4%BC%9A%E5%BD%92%E8%BF%98%E7%BB%99%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%90%97)

malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。

- 方式一：通过 brk() 系统调用从堆分配内存
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存；

方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png)

方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png)

**什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？**

malloc() 源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

注意，不同的 glibc 版本定义的阈值也是不同的。

**malloc() 分配的是物理内存吗？**

不是的，malloc() 分配的是*虚拟内存*。

如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。

**malloc(1) 会分配多大的虚拟内存？**

malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是会预分配更大的空间作为内存池。

具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系，我们就以 malloc 默认的内存管理器（Ptmalloc2）来分析。

malloc(1) 实际上预分配 132K 字节的内存。

**malloc 申请的内存，free 释放内存会归还给操作系统吗？**

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；
- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。

**为什么不全部使用 mmap 来分配内存？**

频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大。

为了改进这两个问题，malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。

等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗。

**为什么不全部使用 brk 来分配？**

前面我们提到通过 brk 从堆空间分配的内存，并不会归还给操作系统，那么我们那考虑这样一个场景。

如果我们连续申请了 10k，20k，30k 这三片内存，如果 10k 和 20k 这两片释放了，变为了空闲内存空间，如果下次申请的内存小于 30k，那么就可以重用这个空闲内存空间。

但是如果下次申请的内存大于 30k，没有可用的空闲内存空间，必须向 OS 申请，实际使用内存继续增大。

因此，随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。

所以，malloc 实现中，充分考虑了 brk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间。

## 03.C++头文件“<>”和“ “” ”的区别

<>和"“表示编译器在搜索头文件时的顺序不同

<>表示从系统目录下开始搜索，然后再搜索PATH环境变量所列出的目录，不搜索当前目录

”“是表示从当前目录开始搜索，然后是系统目录和PATH环境变量所列出的目录。

所以，系统头文件一般用<>，用户自己定义的则可以使用”"，加快搜索速度。

## 04.堆和栈的区别

- 申请方式不同。
  - 栈由系统自动分配。
  - 堆是自己申请和释放的。

- 申请大小限制不同。
  - 栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，由ulimit -s修改。
  - 堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。
- 申请效率不同。
  - 栈由系统分配，速度快，不会有碎片。
  - 堆由程序员分配，速度慢，且会有碎片。
- 存储内容不同
  - 栈在函数调用时，函数调用语句的下一条可执行语句的地址第一个进栈，然后函数的各个参数进栈，其中静态变量是不入栈的。
  - 而堆一般是在头部用一个字节存放堆的大小，堆中的具体内容是人为安排;
- 底层不同
  - 栈是连续的空间
  - 堆是不连续的空间

| 堆               | 栈                                                           |                                                              |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **管理方式**     | 堆中资源由程序员控制（容易产生memory leak）                  | 栈资源由编译器自动管理，无需手工控制                         |
| **内存管理机制** | 系统有一个记录空闲内存地址的链表，当系统收到程序申请时，遍历该链表，寻找第一个空间大于申请空间的堆结点，删 除空闲结点链表中的该结点，并将该结点空间分配给程序（大多数系统会在这块内存空间首地址记录本次分配的大小，这样delete才能正确释放本内存空间，另外系统会将多余的部分重新放入空闲链表中） | 只要栈的剩余空间大于所申请空间，系统为程序提供内存，否则报异常提示栈溢出。（这一块理解一下链表和队列的区别，不连续空间和连续空间的区别，应该就比较好理解这两种机制的区别了） |
| **空间大小**     | 堆是不连续的内存区域（因为系统是用链表来存储空闲内存地址，自然不是连续的），堆大小受限于计算机系统中有效的虚拟内存（32bit 系统理论上是4G），所以堆的空间比较灵活，比较大 | 栈是一块连续的内存区域，大小是操作系统预定好的，windows下栈大小是2M（也有是1M，在 编译时确定，VC中可设置） |
| **碎片问题**     | 对于堆，频繁的new/delete会造成大量碎片，使程序效率降低       | 对于栈，它是有点类似于数据结构上的一个先进后出的栈，进出一一对应，不会产生碎片。（看到这里我突然明白了为什么面试官在问我堆和栈的区别之前先问了我栈和队列的区别） |
| **生长方向**     | 堆向上，向高地址方向增长。                                   | 栈向下，向低地址方向增长。                                   |
| **分配方式**     | 堆都是动态分配（没有静态分配的堆）                           | 栈有静态分配和动态分配，静态分配由编译器完成（如局部变量分配），动态分配由alloca函数分配，但栈的动态分配的资源由编译器进行释放，无需程序员实现。 |
| **分配效率**     | 堆由C/C++函数库提供，机制很复杂。所以堆的效率比栈低很多。    | 栈是其系统提供的数据结构，计算机在底层对栈提供支持，分配专门 寄存器存放栈地址，栈操作有专门指令。 |

## 05.内存泄漏

**1) 内存泄漏**

内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制；

**2) 后果**

只发生一次小的内存泄漏可能不被注意，但泄漏大量内存的程序将会出现各种证照：性能下降到内存逐渐用完，导致另一个程序失败；

**3）解决方法**

智能指针、RAII机制

RAII，即Resource Acquisition Is Initialization，在初始化中获取资源。

RAII机制，通过在栈上创建临时变量，这样临时变量就接管了堆上内存的控制权，当该临时变量声明周期结束时，则对应的堆上内存自然就被释放了。

## 06.常用设计模式

**1.单例模式**

一个类只有一个实例，且该类能自行创建这个实例的一种模式，单例类对外提供一个访问该单例的全局访问点

优点：单例模式可以保证内存里只有一个实例，减少了内存的开销。
        	可以避免对资源的多重占用。
        	单例模式设置全局访问点，可以优化和共享资源的访问。

缺点：单例模式一般没有接口，扩展困难。
       	单例模式的功能代码通常写在一个类中，如果功能设计不合理，则很容易违背单一职责原则

***饿汉式单例***：类一旦加载就创建一个单例，保证在调用getInstance方法之前单例已经存在，这种饿汉式单例会造成空间浪费。

***懒汉式单例***：为了避免内存空间浪费，采用懒汉式单例，即用到该单例对象的时候再创建。

**2、工厂方法模式**

实例化对象不是用new，用工厂方法替代。

将选择实现类，创建对象统一管理和控制。从而将调用者跟我们的实现类解耦。

***简单工厂模式***：用来生产同一等级架构中的任意产品(对于增加新的产品，需要修改已有代码)

***工厂方法模式***：用来生产同一等级架构中的固定产品，一个工厂等级结构可以负责多个不同产品等级结构中的产品对象的创建 。(支持增加任意产品)

简单工厂模式与工厂方法模式比较：

*结构的复杂度*：简单工厂模式占优。
*代码的复杂度*：简单工厂模式占优。
*编程的复杂度*：简单工厂模式占优。
*管理的复杂的*：简单工厂模式占优。
因此，虽然简单工厂模式不符合设计模式，但是实际使用远大于工厂方法模式。

**3、代理模式**

由于某些原因需要给某对象提供一个代理以控制对该对象的访问。

这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。

***静态代理模式：***

角色分析：

1、抽象角色：一般会使用接口或抽象类来解决

2、真实角色：被代理的角色

3、代理角色：代理真实角色，代理真实角色后我们会进行一些附属操作

4、访问角色：访问代理对象的人

代理模式优点：可以使真实角色的操作更加纯粹!不用去关注一些公共的业务，公共也就可以交给代理角色，实现了业务的分工，公共业务发生扩展的时候，方便集中管理!
代理模式缺点：一个真实角色就会产生一个代理角色;代码量会翻倍开发效率会变低，也许，这样无法理解到代理模式的好处。举个例子也许能更好理解，比如说我们想要在原有固定功能上新增业务，按照开闭原则我们是不能对原有代码进行修改的。但是我们可以通过代理模式，增加代理，在实现原有功能的情况下写入新的功能，创建对象时也就可以使用代理，完成操作。

***动态代理模式（不全）***

虽然静态代理模式可以很好的解决开闭原则，但是每有一个真实角色就会产生一个代理，代码量翻倍过于臃肿，开发效率较低。

# 操作系统

## [01.进程的三种状态](https://xiaolincoding.com/os/4_process/process_base.html#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81)

![进程的三种基本状态](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg)

**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态**

- **就绪状态（*Ready*）：**进程已获得除CPU外的所有必要资源，只等待CPU时的状态。一个系统会将多个处于就绪状态的进程排成一个就绪队列。
- **运行状态（*Running*）：**进程已获CPU，正在执行。单处理机系统中，处于执行状态的进程只一个；多处理机系统中，有多个处于执行状态的进程。
- **阻塞状态（*Blocked*）：**正在执行的进程由于某种原因而暂时无法继续执行，便放弃处理机而处于暂停状态，即进程执行受阻。（这种状态又称等待状态或封锁状态）

**当然，进程还有另外两个基本状态：**

- **创建状态（*new*）：**进程正在被创建时的状态；
- **结束状态（*Exit*）：**进程正在从系统中消失时的状态；

![进程五种状态的变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg)

- *NULL -> 创建状态*：一个新进程被创建时的第一个状态；
- *创建状态 -> 就绪状态*：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
- *就绪态 -> 运行状态*：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
- *运行状态 -> 结束状态*：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
- *运行状态 -> 就绪状态*：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
- *运行状态 -> 阻塞状态*：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
- *阻塞状态 -> 就绪状态*：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

## [02.进程和线程的区别](https://xiaolincoding.com/os/4_process/process_base.html#%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%AF%94%E8%BE%83)

- 进程是资源分配的最小单位，线程是程序执行的最小单位。
- 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
- 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。
- 多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

## [03. 线程和进程的同步机制](https://xiaolincoding.com/os/4_process/process_commu.html#%E7%AE%A1%E9%81%93)

### 线程间通信

**1、 互斥量/互斥锁（CMutex）**

互斥量多用于多进程之间的线程互斥，用来确保一个线程独占一个资源的访问

```C++
int pthread_mutex_init(pthread_mutex_t *mutex,const pthread_mutex_attr_t *mutexattr);
int pthread_mutex_lock(pthread_mutex *mutex);
int pthread_mutex_destroy(pthread_mutex *mutex);
int pthread_mutex_unlock(pthread_mutex *)
```

**2、 事件（CEvent）/条件变量**

事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。或者按照条件变量的说法，提供线程之间的一种通知机制。
每个Cevent对象可以有两种状态：有信号状态和无信号状态。
Cevent类对象有两种类型：人工事件和自动事件。

```C++
int pthread_cond_init(pthread_cond_t *cond,pthread_condattr_t *cond_attr);     
int pthread_cond_wait(pthread_cond_t *cond,pthread_mutex_t *mutex);
int pthread_cond_timewait(pthread_cond_t *cond,pthread_mutex *mutex,const timespec *abstime);
int pthread_cond_destroy(pthread_cond_t *cond);  
int pthread_cond_signal(pthread_cond_t *cond);
int pthread_cond_broadcast(pthread_cond_t *cond);  //解除所有线程的阻塞
```

**3、信号量（CSemphore）**

当需要一个计数器来限制可以使用某共享资源的线程数目时，可以使用“信号量”对象。
信号量提供对临界资源的安全分配。如果存在多份临界资源，在多个线程争抢临界资源的情况下，向线程提供安全分配临界资源的方法。如果临界资源的数量为1，将退化为锁。

IPC方式中也有信号量，常常配合ipc共享内存来使用，作为进程之间以及同一进程不同线程间的同步手段。

使用方式：
CSemaphore类对象保存了对当前访问某一个指定资源的线程的计数值，该计数值是当前还可以使用该资源的线程数目。如果这个计数达到了零，则所有对这个CSemaphore类对象所控制的资源的访问尝试都被放入到一个队列中等待，直到超时或计数值不为零为止。线程在处理完共享资源后，应在离开的同时通过ReleaseSemaphore（）函数将当前可用资源数加1。

```C++
#include <semaphore.h>
int sem_init (sem_t *sem , int pshared, unsigned int value);
int sem_wait(sem_t *sem);
int sem_post(sem_t *sem);
int sem_destroy(sem_t *sem);
```

### 进程间通信

- 管道：
  - 无名管道（内存文件）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用。进程的亲缘关系通常是指父子进程关系。
  - 有名管道（FIFO文件，借助文件系统）：有名管道也是半双工的通信方式，但是允许在没有亲缘关系的进程之间使用，管道是先进先出的通信方式。
- 共享内存：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与信号量，配合使用来实现进程间的同步和通信。
- 消息队列：消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
- 套接字：适用于不同机器间进程通信，在本地也可作为两个进程通信的方式。
- 信号：用于通知接收进程某个事件已经发生，比如按下ctrl + C就是信号。
- 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

## [04.虚拟地址](https://xiaolincoding.com/os/3_memory/vmem.html#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98)

为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套**虚拟地址空间**，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。

每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过**内存交换**技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。

那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。

那么对于虚拟地址与物理地址的映射关系，可以有**分段**和**分页**的方式，同时两者结合都是可以的。

内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。

于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 `4KB`。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。

再来，为了解决简单分页产生的页表过大的问题，就有了**多级页表**，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的**局部性原理**，在 CPU 芯片中加入了 **TLB**，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。

**Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理**。于是 Linux 就把所有段的基地址设为 `0`，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。

另外，Linux 系统中虚拟空间分布可分为**用户态**和**内核态**两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。

> 虚拟内存有什么作用？

- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

## 05.父子进程间的关系

**父进程**

已创建一个或多个子进程的进程

**子进程**

由fork创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是0，而父进程的返回值则是新进程（子进程）的进程 id。

将子进程id返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程id。对子进程来说，之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid；也可以调用getppid()来获取父进程的id。(进程id 0总是由交换进程使用，所以一个子进程的进程id不可能为0 )。

fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数器pc值相同，也就是说，子进程是从fork返回处开始执行的），但有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。

**子进程从父进程继承的有**

1.进程的资格(真实(real)/有效(effective)/已保存(saved)用户号(UIDs)和组号(GIDs))

2.环境(environment)

3.堆栈

4.内存

5.进程组号

独有：

1.进程号；

2.不同的父进程号(译者注：即子进程的父进程号与父进程的父进程号不同， 父进程号可由getppid函数得到)；

3.资源使用(resource utilizations)设定为0

**进程组**

进程组就是多个进程的集合，其中肯定有一个组长，其进程PID等于进程组的PGID。只要在某个进程组中一个进程存在，该进程组就存在，这与其组长进程是否终止无关。

**会话**

会话（Session）是一个或多个进程组的集合。一个会话可以有一个控制终端。在xshell或者WinSCP中打开一个窗口就是新建一个会话。

# 计算机网络

## [01.TCP三次握手和四次挥手](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#tcp-%E5%A4%B4%E6%A0%BC%E5%BC%8F%E6%9C%89%E5%93%AA%E4%BA%9B)

### TCP基本认识

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzguanBn?x-oss-process=image/format,png)

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。

***什么是TCP连接？***

用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括**Socket、序列号和窗口大小**称为连接。

所以我们可以知道，建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。

- **Socket**：由 IP 地址和端口号组成
- **序列号**：用来解决乱序问题等
- **窗口大小**：用来做流量控制

***如何唯一确定一个 TCP 连接呢？***

TCP 四元组可以唯一的确定一个连接，四元组包括如下：

- 源地址
- 源端口
- 目的地址
- 目的端口

![TCP 四元组](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEwLmpwZw?x-oss-process=image/format,png)

源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。

源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。

### UDP 和 TCP 的区别与应用场景

UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。

**TCP 和 UDP 区别：**

***1. 连接***

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

***2. 服务对象***

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

***3. 可靠性***

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

***4. 拥塞控制、流量控制***

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

***5. 首部开销***

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

***6. 传输方式***

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

***7. 分片不同***

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

### 三次握手

**握手过程**

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的**。三次握手的过程如下图：

- 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态

- 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。

- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。
- 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

**为什么是三次握手？**

- 三次握手才可以阻止重复历史连接的初始化（主要原因）
- 三次握手才可以同步双方的初始序列号
- 三次握手才可以避免资源浪费

### 四次挥手

**挥手过程**

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

**为什么是四次挥手？**

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

## 02.网络编程常用的API

 **1. 创建套接字（socket函数）**

```C++
int socket(int domain, int type, int protocol);
- 第一个参数domain：指定协议族
- 第二个参数type:指定这个套接字的通信类型
- 第三个参数address_lenprotocol：指定使用的协议，设置为0表示使用默认协议。
返回值：成功返回套接字文件描述符，失败返回-1
作用：系统调用创建一个套接字并返回一个描述符，该描述符可以用来访问该套接字。
```

**2. 通用套接字数据结构（sockaddr）**

套接字编程需要指定套接字的地址作为参数，不同的协议族有不同的地址结构定义方式。例如以太网，其结构名称为sockaddr_in。

sockaddr为通用套接字数据结构，它可以在不同协议族之间进行强制转换。可以认为其他的地址结构都是由它进行细分出来的。

```c++
struct sockaddr{                    /* 套接字地址结构 */
    sa_family_t sun_family;         /* 协议族 */
    char            sa_data[14];    /* 协议族数据 */
}；            
typedef unsigned short sa_family_t；   /* 16位 */
```

**3. 以太网常用的地址结构（sockaddr_in）**

```C++
struct sockaddr_in{
   short int                 sin_family;    /* 协议族，以太网一般位AF_INET */
　 unsigned short int        sin_port;      /* 16位的端口号，网络字节序 */
　 struct in_addr           sin_addr;       /* IP地址32位 */
   char                    sin_zero[8];    /* 保留 */
};
```

由于结构struct sockaddr和结构struct sockaddr_in的大小是完全一致的，所以进行地址结构设置时，通常的方法是利用结构struct sockaddr_in进行设置，然后强制转换为结构struct sockaddr类型。因为这两个结构大小是完全一致的，所以进行这样的转换不会有副作用。

**4. 命名套接字（bind函数）**

```c++
#include <sys/socket.h>
#include <sys/types.h>
int bind(int socket, const struct sockaddr *address, size_t address_len);
- 第一个参数socket：由socket()函数创建得到得套接字描述符
- 第二个参数address：我们指定要绑定的域、IP地址和端口的sockaddr结构体
- 第三个参数address_len：sockaddr结构体的长度。通常使用sizeof(struct sockaddr)
返回值：0表示绑定成功，-1表示绑定失败。可以通过error查看错误值
作用：bind系统调用把参数address中的地址分配给与文件描述符socket关联。
```

**5. 创建套接字队列（listen函数）**

```C++
#include <sys/socket.h>
#include <sys/types.h>
int listen(int socket, int backlog);
第二个参数backlog：等待处理的进入连接的个数最多不能超过这个数字
返回值： 成功：0； 失败：-1；
作用：初始化服务器可连接队列，服务器处理客户端连接请求的时候是顺序处理的，同一时间仅能处理一个客户端连接。当多个客户端的连接请求同时到来的时候，服务器并不是同时处理，而是将不能处理的客户端连接请求放到等待队列中，这个队列的长度由listen()函数来定义。
```

**6. 接收连接（accept函数）**

```c++
#include <sys/socket.h>#include <sys/types.h>
int accept(int socket, struct sockaddr *address, size_t *address_len);　　
参数：当accept()函数返回的时候，会将客户端的信息存储在参数address中。
参数：address_len表示第二个参数所指内容的长度，可以使用sizeof(struct sockaddr_in)来获得。　　
需要注意的是：在accept中address_len参数是一个指针而不是结构，accept()函数将这个指针传给TCP/IP协议栈。　　
返回值：成功返回新的描述符用于和客户端进行通信。失败返回-1。
作用：只有当有客户程序试图连接到由socket参数指定的套接字上时才返回。这里的客户是指，在套接字队列中排在第一个的未处理连接。accpet函数将创建一个新的套接字来与该客户进行通信，并且返回新套接字的描述符。
```

**7. 请求连接（connect函数）**

```C++
#include <sys/socket.h>
int connect(int socket, const struct sockaddr *address, size_t address_len);参数：　　
- 第一个参数socket：建立套接字的时候返回的描述符　　
- 第二个参数address：一个指向数据结构sockaddr的指针，其中包括客户端需要连接的服务器的目的端口和ip地址，以及协议类型。　　
- 第三个参数address_len：表示第二个参数内容的大小，可以使用sizeof(struct sockaddr)获得，与bind函数不同，这个参数是一个整形的变量而不是指针。
返回值： 成功：0； 失败：-1
作用：参数socket指定的套接字将连接到参数address指定的服务器套接字，address指向的结构的长度由参数address_len指定。
```

**8. 写入数据函数（write，send，writev）**

```C++
int size 
char data[1024];
size = write(socket, data, 1024);    //将缓冲区data的数据全部写入套接字描述符socket中，返回值为成功写入的数据长度。　　注意：如果用tcp，socket是accept函数返回的套接字描述符。
```

```C++
#include <sys/types.h>
#include <sys/socket.h>

ssize_t send(int s, const void *buf, size_t len, int flags);
参数：和recv的参数基本一致。返回值：成功发送的字节数。发生错误的返回-1，可以查看errno获取错误码。
    
由于用户缓冲区buf中的数据在通过send()函数进行发送的时候，并不一定能够全部发送，所以要检查send()函数的返回值，按照与计划发送的字节长度len是否相等来判断如何进行下一步操作。
当send()函数的返回值小于len的时候，表明缓冲区中仍然有部分数据没有成功发送，这时需要重新发送剩余部分的数据。通常的剩余数据发送方法是对原来buf中的数据位置进行偏移，偏移的大小为已发送成功的字节数。
```

```C++
#include <sys/uio.h>
ssize_t writev(int fd, const srtuct iovec *vector, int count);
struct iovec{　　
	void *iov_base;　　　　/* 向量的缓冲区地址 */　　
	size_t iov_len;　　　　/* 向量缓冲区的大小，以字节为单位 */
};
作用：向套接字描述符s中写入在向量vector中保存的count块数据。
返回值：成功返回发送的字节数。错误返回-1，可以查看errno获取错误码。
```

**9. 读取数据函数（read，recv，readv）**

```C++
int size;
char data[1024];
size = read(socket, data, 1024);    
从套接字描述符socket中读取1024个字节，放入缓冲区data中，返回值是成功读取的数据大小
```

```c++
#include <sys/types.h>
#include <sys/socket.h>

ssize_t recv(int s, void *buf, size_t len, int flags);
参数：　　
	s：由socket函数得到得套接字描述符。　　
	buf：从套接字s中接收数据放在缓冲区buf中。　　
	len：buf的长度　　
	flag：用于设置接收数据的方式返回值：　　
错误返回-1，可以查看errno。成功返回接收的字节数。
recv()函数通常用于TCP类型，UDP使用recvfrom()函数接收数据，当然在数据报套接字绑定地址和端口后，也可以使用recv()函数接收数据。
```

```C++
#include <sys/uio.h>
ssize_t readv(int s, const struct iovec *vector, int count);
struct iovec{　　
	void *iov_base;　　　　　　/* 向量的缓冲区地址 */　　
	size_t iov_len;　　　　　　/* 向量缓冲区的大小，以字节为单位 */
};
作用：从套接字描述符s中读取count块数据放在缓冲区向量vector中。
返回值：成功接收到的字节数。错误返回-1，查看errno获取错误码。
```

**10. 关闭套接字函数（close，shutdown）**

```C++
#include <sys/socket.h>

int shutdown(int socket, int how);
参数：
	第一个参数是要切换通信的套接字描述符。　　
	第二个参数表示切断的方式。　　
		SHUT_RD:值为0，表示切断读。　　
		SHUT_WR:值为1，表示切断写。　　
		SHUT_RDWR:值为2，表示切换读写。
	返回值：成功返回0，失败返回-1
或者
close(socket);
close函数：关闭已经打开的socket连接，内核会释放相关的资源，关闭套接字之后就不能再使用这个套接字文件描述符进行读写操作。
shutdown函数：允许单方向切断通信或者切断双方的通信。
```

## [03.IO多路复用](https://xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84-socket-%E6%A8%A1%E5%9E%8B)

最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I/O 模型。

比较传统的方式是使用多进程/线程模型，每来一个客户端连接，就分配一个进程/线程，然后后续的读写都在对应的进程/线程，这种方式处理 100 个客户端没问题，但是当客户端增大到 10000 个时，10000 个进程/线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈。

为了解决上面这个问题，就出现了 I/O 的多路复用，可以只在一个进程里处理多个文件的 I/O，Linux 下有三种提供 I/O 多路复用的 API，分别是： select、poll、epoll。

select 和 poll 并没有本质区别，它们内部都是使用「线性结构」来存储进程关注的 Socket 集合。

在使用的时候，首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。

很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K。

epoll 是解决 C10K 问题的利器，通过两个方面解决了 select/poll 的问题。

- epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。
- epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。

而且，epoll 支持边缘触发和水平触发的方式，而 select/poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。
